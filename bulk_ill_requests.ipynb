{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d15d82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries.\n",
      "Script started.\n",
      "Cleaning data.\n",
      "Parsing XML.\n",
      "Sending requests to Alma:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab706567935b43c785e5cc7abdd853d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 records processed, please wait for responses to be saved to xlsx file...\n",
      "Response file saved as: Bulk_ill_request_response.xlsx.\n"
     ]
    }
   ],
   "source": [
    "#Bulk ILL uploader, Places resource sharing requests via API, requests sumbmitted as a reference manager XML file.\n",
    "#Script outputs xlsx and csv files.\n",
    "#Author Rachel Merrick.\n",
    "#Originally written and executed with Anaconda/Jupyter:\n",
    "#Some libraries may need to be installed before running the script in other environments.\n",
    "\n",
    "#Output to indicate where the script is up to.\n",
    "print('Importing libraries.')\n",
    "#Import required libraries/modules.import requests as req #Used to to access Alma API.\n",
    "import requests as req #Used to to access Alma API.\n",
    "from requests.structures import CaseInsensitiveDict #used to create and send JSON request data object.\n",
    "import xml.etree.ElementTree as ET #Used to parse XML file.\n",
    "import pandas as pd #Used to create data frame.\n",
    "import re #Allows use of regular expresions which have been used to extract error messages.\n",
    "from ipywidgets import IntProgress #Used for progress bar\n",
    "from IPython.display import display #Used for progress bar\n",
    "\n",
    "#Function that tests if an element in an XML path is pressent and adds element or empty string to a list.\n",
    "#List is returned to the main program.\n",
    "def get_element(path, root):\n",
    "    element_list = []\n",
    "    for record in root.iter('record'):\n",
    "        element = record.find(path)\n",
    "        if element is not None:\n",
    "            element = record.find(path).text\n",
    "            element = element.replace('\"','\\\\\\\"') #Add JSON escape character infront of double quotes.\n",
    "        else:\n",
    "            element = \"\"\n",
    "        element_list.append(element)\n",
    "    return(element_list)\n",
    "\n",
    "#Function that returns a list of an XML element's attribute to the main program. \n",
    "def get_attribute(path, attribute_type, root):\n",
    "    attribute_list = []\n",
    "    for element in root.iter(path):\n",
    "        attribute = element.get(attribute_type)\n",
    "        attribute = attribute.replace('\"','\\\\\\\"') #Add JSON escape character infront of double quotes.\n",
    "        attribute_list.append(attribute)\n",
    "    return(attribute_list)\n",
    "\n",
    "#Main program.\n",
    "def main():\n",
    "    #Output to indicate where the script is up to.\n",
    "    print('Script started.')\n",
    "    \n",
    "    #The following variables will need to be checked and added/edited before running the script.\n",
    "    user_id = 'Enter primary ID' #Requester's Alma primary identifier\n",
    "    file_name = 'Enter XML file name'#File name containing citation being requested\n",
    "    \n",
    "    #Variables used to send API request.\n",
    "    key = '' #Alma production API key. - add your requests key\n",
    "    headers = CaseInsensitiveDict() #Used to send JSON portfolio object.\n",
    "    headers[\"Content-Type\"] = \"application/json; charset=utf-8\" #Used to send JSON portfolio object.\n",
    "    url = (\"https://api-ap.hosted.exlibrisgroup.com/almaws/v1/users/\"+user_id + \n",
    "                \"/resource-sharing-requests?override_blocks=false&apikey=\"+ key) #API request URL.\n",
    "\n",
    "    #Variables used to detect and report errors and other messages.\n",
    "    url_error = '<errorsExist>true</errorsExist>' #Test to indicate when an error is pressent in API request url.\n",
    "    error_message = '<errorMessage>(.+)</errorMessage>' #Extracting the error message from API response.\n",
    "    data_object_error = '\"errorsExist\":true' #Test to indicate when an error is pressent in JSON data object.\n",
    "    #Test to indicate when an request ID is pressent in JSON data object.\n",
    "    internal_request_id = '<request_id>(.+)</request_id>'\n",
    "\n",
    "    #Output to indicate where the script is up to.\n",
    "    print('Cleaning data.')\n",
    "    \n",
    "    #Read request file\n",
    "    with open(file_name, 'r', encoding=\"utf8\") as file :\n",
    "        filedata = file.read()\n",
    "\n",
    "    #Remove any XML style tags from EndNote libraries.\n",
    "    filedata = filedata.replace('<style face=\"normal\" font=\"default\" size=\"100%\">', '')\n",
    "    filedata = filedata.replace('</style>', '')\n",
    "    #Remove line breaks, carriage returns, spacing which shouldn't be sent in the JSON data object.\n",
    "    filedata = filedata.replace('\\n', '')\n",
    "    filedata = filedata.replace('&#xD', '')\n",
    "    filedata = filedata.replace('&#xA', '')\n",
    "    filedata = filedata.replace('\\r', '')\n",
    "    filedata = filedata.replace('\\t', '')\n",
    "    filedata = filedata.replace('            ', '')\n",
    "\n",
    "    # Save over request file with version with style tages removed.\n",
    "    with open(file_name, 'w', encoding=\"utf8\") as file:\n",
    "        file.write(filedata)\n",
    "        file.close()\n",
    "\n",
    "    #Parse request file, assign tree and root variables.\n",
    "    tree = ET.parse(file_name)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    #Output to indicate where the script is up to.\n",
    "    print('Parsing XML.')\n",
    "    \n",
    "    #Call function for required fields sending XML paths. Variables will contain a list of the relevant elements or\n",
    "    #attributes.\n",
    "    all_ref_types = get_attribute('ref-type', 'name', root)\n",
    "    all_primary_titles = get_element('titles/title', root)\n",
    "    all_volumes = get_element('volume', root)\n",
    "    all_secondary_titles = get_element('titles/secondary-title', root)\n",
    "    all_authors = get_element('contributors/authors/author', root)\n",
    "    all_issues = get_element('number', root)\n",
    "    all_issns = get_element('isbn', root)\n",
    "    all_dates = get_element('dates/year', root)\n",
    "    all_publisher = get_element('publisher', root)\n",
    "    all_pages = get_element('pages', root)\n",
    "    all_dois = get_element('electronic-resource-num', root)\n",
    "    all_editions = get_element('edition', root)\n",
    "\n",
    "    #Create data frame which will be used as output showing the API responses.\n",
    "    df_data = {'Article_chapter_title' : all_primary_titles, 'Journal_book_title' : all_secondary_titles,\n",
    "               'Author': all_authors ,'Volume': all_volumes, 'Issue': all_issues, 'Date': all_dates, \n",
    "               'Edition': all_editions ,'ISSN' : all_issns, 'Publisher' :all_publisher, 'Pages': all_pages, \n",
    "               'DOIs': all_dois,'Refernce_type': all_ref_types,'Responses': all_ref_types}\n",
    "    df = pd.DataFrame(df_data, columns=['Article_chapter_title','Journal_book_title','Author','Volume', 'Issue','Date',\n",
    "                                        'Edition','ISSN','Publisher','Pages','DOIs','Refernce_type','Responses'])\n",
    "\n",
    "    #Output to indicate where the script is up to.\n",
    "    print('Sending requests to Alma:')\n",
    "    \n",
    "    #Progress bar.\n",
    "    johns_progress_bar = IntProgress(min=0, max=len(all_ref_types)) # intantiate the bar\n",
    "    display(johns_progress_bar) # display the bar\n",
    "\n",
    "    #Loop to iterate over each citation in the request file by using the attribute lists.\n",
    "    for i in range(len(all_ref_types)):\n",
    "        #If citation type is journal article, conference proceeding or book section.\n",
    "        if (all_ref_types[i] == 'Journal Article' or all_ref_types[i] == 'Conference Proceedings'\n",
    "           or all_ref_types[i] == 'Book Section' or all_ref_types[i] == 'book_section') :\n",
    "            #assign citation being looped over's attributes to variable.\n",
    "            primary_title = all_primary_titles[i]\n",
    "            issn = all_issns[i]\n",
    "            author = all_authors[i]\n",
    "            year = all_dates[i]\n",
    "            publisher = all_publisher[i]\n",
    "            volume = all_volumes[i]\n",
    "            secondary_title = all_secondary_titles[i]\n",
    "            issue = all_issues[i]\n",
    "            pages= all_pages[i]\n",
    "            doi = all_dois[i]\n",
    "            edition = all_editions[i]\n",
    "\n",
    "            #Construct portion of JSON data object for journal articles and conference proceeings using variables\n",
    "            #created by iterating over lists in this loop.\n",
    "            if (all_ref_types[i] == 'Journal Article' or all_ref_types[i] == 'Conference Proceedings'):\n",
    "                excerpt_data = '''\"citation_type\": {\n",
    "        \"value\": \"CR\"\n",
    "      },\n",
    "      \"level_of_service\": {\n",
    "        \"value\": \"WHEN_CONVINIENT\"\n",
    "      },\n",
    "      \"title\": \"'''+ primary_title + '''\",\n",
    "      \"issn\": \"''' + issn + '''\",\n",
    "      \"author\": \"''' + author + '''\",\n",
    "      \"year\": \"''' + year + '''\",\n",
    "      \"publisher\": \"''' + publisher + '''\",\n",
    "      \"volume\": \"''' + volume + '''\",\n",
    "      \"journal_title\": \"''' + secondary_title + '''\",\n",
    "      \"issue\": \"''' + issue + '''\",\n",
    "      \"pages\": \"''' + pages + '''\",\n",
    "      \"doi\": \"''' + doi + '''\"\n",
    "    }\n",
    "    '''\n",
    "            #Construct portion of JSON data object for book sections using variables created by iterating over \n",
    "            #lists in this loop.\n",
    "            else:\n",
    "                    excerpt_data = '''\"citation_type\": {\n",
    "        \"value\": \"BK\"\n",
    "      },\n",
    "      \"level_of_service\": {\n",
    "        \"value\": \"WHEN_CONVINIENT\"\n",
    "      },\n",
    "      \"title\": \"'''+ secondary_title + '''\",\n",
    "      \"isbn\": \"''' + issn + '''\",\n",
    "      \"author\": \"''' + author + '''\",\n",
    "      \"year\": \"''' + year + '''\",\n",
    "      \"publisher\": \"''' + publisher + '''\",\n",
    "      \"edition\": \"''' + edition + '''\",\n",
    "      \"chapter_title\": \"''' + primary_title + '''\",\n",
    "      \"pages\": \"''' + pages + '''\",\n",
    "      \"doi\": \"''' + doi + '''\"\n",
    "    }\n",
    "    '''\n",
    "            #Create full JSON data object which includes a string with generic ILL request with the users ID and the\n",
    "            #book or article portions contained in variables above.\n",
    "            json_data = '''{\n",
    "      \"requester\": {\n",
    "        \"value\": \"''' +user_id + '''\"\n",
    "      },\n",
    "      \"requested_media\": \"7\",\n",
    "      \"format\": {\n",
    "        \"value\": \"DIGITAL\"\n",
    "      },\n",
    "      \"preferred_send_method\": {\n",
    "        \"value\": \"EMAIL\"\n",
    "      },\n",
    "\n",
    "      \"pickup_location_type\": \"LIBRARY\",\n",
    "      \"pickup_location\": {\n",
    "        \"value\": \"nsyd\"\n",
    "      },\n",
    "      \"copyright_status\": {\n",
    "        \"value\": \"APPROVED\"\n",
    "      },\n",
    "      \"agree_to_copyright_terms\": true,\n",
    "      \"willing_to_pay\": false,\n",
    "      ''' + excerpt_data\n",
    "\n",
    "            #Send request using Post URL and data object to Alma. Reponse will be contained in the variable.\n",
    "            response = req.post(url, headers=headers, data=json_data.encode('utf-8'))\n",
    "\n",
    "            #Selection statement if there is an error add error message to notes column of data frame, \n",
    "            #else No errors detected.\n",
    "            #Testing for API url error, if error pressent add error to responses column.\n",
    "            if url_error in response.text:\n",
    "                note = re.search(error_message, response.text)\n",
    "                df.at[i, 'Responses'] = note.group(1)\n",
    "\n",
    "            #Testing for data object error, if error pressent add error to responses column.\n",
    "            elif data_object_error in response.text:\n",
    "                note = response.text\n",
    "                df.at[i, 'Responses'] = 'Error in data sent to API, error message: '+note\n",
    "\n",
    "            #Testing for internal request ID (on all succesful requests) and adding it to responses column.\n",
    "            elif bool(re.search(internal_request_id, response.text)) == True:\n",
    "                note = re.search(internal_request_id, response.text)\n",
    "                df.at[i, 'Responses'] = 'Request created. Internal request id: ' + note.group(1)\n",
    "\n",
    "            #Else request not successfully placed and there is no error message, add uknown response to \n",
    "            #responses column   \n",
    "            else:\n",
    "                note = 'Unkown response'\n",
    "                df.at[i, 'Responses'] = note\n",
    "\n",
    "        #Not a supported reference type skip placing request and any other actions, add note to responses column.\n",
    "        else:\n",
    "            note = 'Unsupported reference type'\n",
    "            df.at[i, 'Responses'] = note\n",
    "\n",
    "        #Save to csv as progresses incase script is interupted.\n",
    "        df.to_csv('Bulk_ill_request_response.csv')\n",
    "\n",
    "        #Increment to progress bar.\n",
    "        johns_progress_bar.value += 1\n",
    "\n",
    "    #Print message of how many records were processed and to wait for xlsx to be written to.\n",
    "    print(str(i + 1) + \" records processed, please wait for responses to be saved to xlsx file...\")\n",
    "\n",
    "    #Create dataframe with count for each response.\n",
    "    df_updated = df.replace(to_replace ='Request created. Internal request id: (.+)', value = 'Request created'\n",
    "                            , regex = True)\n",
    "    counts = df_updated['Responses'].value_counts()\n",
    "\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine- imports another library.\n",
    "    writer = pd.ExcelWriter('Bulk_ill_request_response.xlsx', engine='xlsxwriter')\n",
    "\n",
    "    # Write each dataframe to a different worksheet.\n",
    "    df.to_excel(writer, sheet_name='Detailed')\n",
    "    counts.to_excel(writer, sheet_name='Counts')\n",
    "\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()\n",
    "\n",
    "    #print file save completeion messages. \n",
    "    print(\"Response file saved as: Bulk_ill_request_response.xlsx.\")\n",
    "\n",
    "#Run main program.\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28fd165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
